import pandas as pd
df = pd.read_csv('SMSSpamCollection' , sep ='\t', names=['label','text'])

df

df.shape
(5572, 2)
!pip install nltk
Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)
Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)
Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)
Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)
Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)
import nltk
nltk.download('stopwords')
[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data] Package stopwords is already up-to-date!
True

from nltk.tokenize import word_tokenize
nltk.download('punkt')
[nltk_data] Downloading package punkt to /root/nltk_data...
[nltk_data] Package punkt is already up-to-date!
True
word_tokenize(sent)
['Hello',
'Friends',
'!',
'How',
'are',
'You',
',',
'We',
'will',
'Learn',

03/11/2023, 18:43 Untitled2.ipynb - Colaboratory

https://colab.research.google.com/drive/1f3fVPUuo4ioDdIjjvPzZvJkXzwN-olb6#scrollTo=1P6RPGaBTGCP&uniqifier=1&printMode=true 2/5
'Python',
'Today']
from nltk.corpus import stopwords
sword = stopwords.words('english')
clean = [word for word in word_tokenize(sent) if word not in sword]
clean
['hello', 'friend', '!', 'how', 'you', ',', 'we', 'learn', 'python', 'today']
#stemming-- to remove s,ed,ing(suffixes)
from nltk.stem import PorterStemmer
ps=PorterStemmer()
clean = [ps.stem(word) for word in word_tokenize(sent) if word not in sword]
clean
['hello', 'friend', '!', 'how', 'you', ',', 'we', 'learn', 'python', 'today']
sent = 'Hello Friends! How are You ,We will Learn Python Today'
#text preprocessing
def clean_text(sent):
tokens = word_tokenize(sent)
clean =[word for word in tokens
if word.isdigit() or word.isalpha()]
clean = [ps.stem(word) for word in clean if word not in sword]
return clean
clean_text(sent)
['hello', 'friend', 'how', 'you', 'we', 'learn', 'python', 'today']
#Pre-Processing
#to convert the strings into number tfidf vectorizer is used
from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer(analyzer = clean_text)
#input
x= df['text']
#output
y= df['label']
x_new = tfidf.fit_transform(x)
x.shape
(5572,)
x_new.shape
(5572, 6513)
y.value_counts()
ham 4825
spam 747
Name: label, dtype: int64
#cross validation
from sklearn.model_selection import train_test_split
x_train , x_test,y_train,y_test = train_test_split(x_new,y,random_state=0,test_size=0.25)

03/11/2023, 18:43 Untitled2.ipynb - Colaboratory

https://colab.research.google.com/drive/1f3fVPUuo4ioDdIjjvPzZvJkXzwN-olb6#scrollTo=1P6RPGaBTGCP&uniqifier=1&printMode=true 3/5
x_train.shape
(4179, 6513)
x_test.shape
(1393, 6513)
from sklearn.naive_bayes import GaussianNB

â–¾ GaussianNB
GaussianNB()
nb = GaussianNB()
nb.fit(x_train.toarray(),y_train)

#predicted values
y_pred = nb.predict(x_test.toarray())
#actual values
y_test.value_counts()
ham 1208
spam 185
Name: label, dtype: int64

<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7e3650c31960>
from sklearn.metrics import ConfusionMatrixDisplay
ConfusionMatrixDisplay.from_predictions(y_test,y_pred)

from sklearn.metrics import accuracy_score ,classification_report

precision recall f1-score support\n\n ham 0.98 0.87 0.92 1208\n s
pam 0.51 0.89 0.65 185\n\n accuracy 0.87 1393\n macro avg
0.75 0.88 0.79 1393\nweighted avg 0.92 0.87 0.89 1393\n
'

'

classification_report(y_test,y_pred)

accuracy_score(y_test,y_pred)
0.8729361091170137
#random forest model
from sklearn.ensemble import RandomForestClassifier

03/11/2023, 18:43 Untitled2.ipynb - Colaboratory

https://colab.research.google.com/drive/1f3fVPUuo4ioDdIjjvPzZvJkXzwN-olb6#scrollTo=1P6RPGaBTGCP&uniqifier=1&printMode=true 4/5
rf=RandomForestClassifier()
rf = rf.fit(x_train,y_train)
y_pred = rf.predict(x_test)
ConfusionMatrixDisplay.from_predictions(y_test,y_pred);

print(classification_report(y_test,y_pred))
precision recall f1-score support
ham 0.98 1.00 0.99 1208
spam 1.00 0.86 0.92 185
accuracy 0.98 1393
macro avg 0.99 0.93 0.96 1393
weighted avg 0.98 0.98 0.98 1393

accuracy_score(y_test,y_pred)
0.9813352476669059
#Hyper Parameter Tuning
from sklearn.model_selection import GridSearchCV
params = {
'criterion':['gini', 'entropy','log_loss'],
'max_features': ['sqrt','log2'],
'random_state': [0,1,2,3,4],
'class_weight':['balanced','balanced_subsample']
}
grid =GridSearchCV(rf,param_grid=params,cv=5,scoring='accuracy')
